{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68172cb-c88b-410e-b9bf-0c42cf873a97",
   "metadata": {},
   "source": [
    "# Automatic Feature Engineering\n",
    "This notebook uses a simple heuristic to try and automatically utilize our `ConceptsDriftFinder` tool for feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f1f74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1 - Technical initialization\n",
    "We will start with a few technical dataset loading steps and notebook configuration.\n",
    "\n",
    "We can use here one of 4 different datasets: [\"housing\", \"rain\", \"sales\", \"netflix\"]. See their configuration in `datasets_config.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2666b3c-c651-45ba-85bb-236279845840",
   "metadata": {},
   "source": [
    "### Install necessary requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68768c3-f933-4b8b-bd9f-5bd548c08dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea9b92-6089-4ea1-ad80-d8963977b0a6",
   "metadata": {},
   "source": [
    "### Change working directory and add jupyter reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b2768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change working directory to root\n",
    "import os\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    %cd ..\n",
    "    print(os.getcwd())\n",
    "\n",
    "# Automatically reload changes in code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b045b6a-e402-48ca-9b05-de59b98aa41c",
   "metadata": {},
   "source": [
    "### Imports, logging and pandas configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af51f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from association_finder.concept_drifts_finder import ConceptDriftsFinder\n",
    "from association_finder.models import Transaction, ConceptDriftResult\n",
    "from association_finder.concept_engineering import ConceptEngineering\n",
    "from association_finder.datasets_config import datasets_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from association_finder.preprocessing import preprocess_dataset, split_X_y\n",
    "from association_finder.one_vs_rest_classifier import OneVsRestClassifier, label_to_concept_transform_wrapper\n",
    "from typing import Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logs config\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Pandas config\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bebdb34",
   "metadata": {},
   "source": [
    "### Read, split and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf46346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Dataset can be changed to any of the following: [\"housing\", \"rain\", \"sales\", \"netflix\"]\n",
    "dataset = \"housing\"\n",
    "\n",
    "# load dataset config\n",
    "dataset_config = datasets_config[dataset]\n",
    "\n",
    "# Read file\n",
    "df = pd.read_csv(dataset_config[\"train_dataset_path\"], index_col=dataset_config['index_col'])\n",
    "target_column = dataset_config[\"target_column\"]\n",
    "\n",
    "# Drop rows with NaN values in the target column.\n",
    "df.drop(df[df[target_column].isna()].index,inplace=True)\n",
    "\n",
    "# Rain hotfix\n",
    "if dataset == \"rain\":\n",
    "    # Turn Yes/No columns into 1/0 columns, respectively.\n",
    "    for column in [\"RainToday\", \"RainTomorrow\"]:\n",
    "        df[column] = df[column].map(dict(Yes=1, No=0))\n",
    "\n",
    "# Split\n",
    "df_train, df_val = train_test_split(df, test_size=0.3, random_state=0)\n",
    "\n",
    "# Preprocess    \n",
    "df_train_prep, train_params = preprocess_dataset(df_train)\n",
    "\n",
    "# Focusing on prominent columns:\n",
    "good_columns = [column for column in dataset_config[\"good_columns\"] if column not in train_params.dropped_columns]\n",
    "one_hot_columns = [column for column in dataset_config[\"one_hot_columns\"] if column not in train_params.dropped_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d2b1c-792d-4666-a068-78e2fc502c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "X_train, y_train = split_X_y(df_train_prep, good_columns, train_params, one_hot_columns, target_column)\n",
    "X_val, y_val = split_X_y(preprocess_dataset(df_val, train_params)[0], good_columns, train_params, one_hot_columns, target_column, list(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83204ff8-bbaa-4640-96d1-086ad123c9af",
   "metadata": {},
   "source": [
    "# Step 2 - Find rules\n",
    "\n",
    "In this step, we will automatically try to run `ConceptDriftsFinder` over all the features as concepts. This is one functionallity already bundled in the `ConceptEngineering` object.\n",
    "\n",
    "The output is a dataframe of all the concepts found. This may take a while, especially in the housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1ffa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find association rules\n",
    "concept_engineering = ConceptEngineering(min_confidence=dataset_config['min_confidence'], min_support=dataset_config['min_support'], diff_threshold=dataset_config['diff_threshold'])\n",
    "concept_engineering.fit(X_train, df_train_prep[good_columns], target_column, one_hot_columns)\n",
    "concept_engineering.concepts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8003d16d-79dc-43ec-89a9-6cee0083bcc3",
   "metadata": {},
   "source": [
    "# Step 3 - Build models\n",
    "We could review the concepts dataframe manually, but in this notebook our goal is to automatically evaluate our tool, so what we do now is build 2 models: (1) baseline model (2) a model that uses our tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e4075e",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "The baseline model is a very simple scikit learn one-vs-rest. Accuracy is printed for both train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549b15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple one vs rest classifier for baseline\n",
    "one_vs_rest_classifier = OneVsRestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c8bc0-8604-40c4-82cc-087f031b530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = one_vs_rest_classifier.fit_transform(X_train, y_train)\n",
    "y_val_pred = one_vs_rest_classifier.transform(X_val)\n",
    "\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred)}\")\n",
    "print(f\"Validation accuracy: {accuracy_score(y_val, y_val_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50838547",
   "metadata": {},
   "source": [
    "### Model using rules\n",
    "We now build a model that uses our rules.\n",
    "Again, we use the same scikit learn one-vs-rest.\n",
    "However, this time, for each label we use our `ConceptEngineering` utility.\n",
    "\n",
    "What the `ConceptEngineering` utility does is: (See more details in the accompayning pdf)\n",
    "1) find which slice of the dataset (remember that we slice the dataset using the concept column and the concept cutoff) has higher lift values for the given rule.\n",
    "2) run over all the datapoints in the slice, and increase the values of the features in the left_hand_side of the rule by the difference of the lift values.\n",
    "\n",
    "\n",
    "Accuracy is again printed for both train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24962847-fec2-474f-b824-fd867e7fad4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One vs rest classifier that uses rules (each label classifier uses its own rules)\n",
    "label_to_transformation = {label: label_to_concept_transform_wrapper(concept_engineering, target_column, label) for label in y_train.unique()}\n",
    "rules_one_vs_rest_classifier = OneVsRestClassifier(label_to_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb13c41-52a5-4682-ab8a-89c4ed5bc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_y_train_pred = rules_one_vs_rest_classifier.fit_transform(X_train, y_train)\n",
    "rules_y_val_pred = rules_one_vs_rest_classifier.transform(X_val)\n",
    "\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, rules_y_train_pred)}\")\n",
    "print(f\"Validation accuracy: {accuracy_score(y_val, rules_y_val_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af69f2b-a6d5-44b9-ac63-abb3ee5258ff",
   "metadata": {},
   "source": [
    "# Step 4 - Analyze model\n",
    "We used these steps to monitor the model's behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325bb8bc-0c5f-4602-a8bd-bee248d3ba4f",
   "metadata": {},
   "source": [
    "### Error analysis\n",
    "Prints the errors the model made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae9929-2b99-4ee7-bb02-386d3012e7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(zip(y_train_pred, y_train), columns=['predict', 'actual'], index=X_train.index)\n",
    "pred_df = pd.merge(pred_df, X_train, left_index=True, right_index=True)\n",
    "errors_df = pred_df[pred_df['predict'] != pred_df['actual']]\n",
    "errors_df[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22499a4-3b44-4b1f-93c3-6d6f5f659fc5",
   "metadata": {},
   "source": [
    "### Model coefficients analysis\n",
    "Prints the coefficient of both models. In a one-vs-rest there are models as the number of labels, so you need to specify which model coefficients to see.\n",
    "\n",
    "This is useful to make sure that the rules-using model actually changes the weights for the features in the left hand side of the concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cdc22f-1e36-401b-b906-a70971703c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_label = 3\n",
    "print(list(enumerate(sorted(list(zip(one_vs_rest_classifier.classifiers[model_label].coef_, X_train.columns))))))\n",
    "print(list(enumerate(sorted(list(zip(rules_one_vs_rest_classifier.classifiers[model_label].coef_, X_train.columns))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb898e2-6412-4f4e-beba-b2c934b44ad5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scatterplots\n",
    "Print scatterplots betwen the target and every left hand side feature, before and after the concept values.\n",
    "This is helpful to better understand the effect of each concept on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79609b5-de65-4ad0-97f2-5dee55999885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "combined_df = pd.merge(X_train, y_train, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "for _, concept_row in list(concept_engineering.concepts_df.iterrows()):\n",
    "    print()\n",
    "    print(f\"{concept_row.concept_column} {concept_row.concept_cutoff} {concept_row.right_hand_side}\")\n",
    "    x = concept_engineering._filter_X_by_concept(combined_df, concept_row)\n",
    "    left_hand_side_column = list(concept_row.left_hand_side.keys())[0]\n",
    "    left_hand_side_column_value = list(concept_row.left_hand_side.values())[0]    \n",
    "    \n",
    "    if left_hand_side_column in concept_engineering.one_hot_columns:\n",
    "        left_hand_side_column = f'{left_hand_side_column}_{left_hand_side_column_value}'\n",
    "    \n",
    "    x_filtered = x[left_hand_side_column]\n",
    "    y_filtered = x[target_column]\n",
    "    \n",
    "    x_all = combined_df[left_hand_side_column]\n",
    "    y_all = combined_df[target_column]\n",
    "    \n",
    "    # count the occurrences of each point\n",
    "    c = Counter(zip(x_all,y_all))\n",
    "    # create a list of the sizes, here multiplied by 10 for scale\n",
    "    s = [10*c[(xx,yy)] for xx,yy in zip(x_all,y_all)]\n",
    "    plt.scatter(x_all, y_all, s=s, color='blue')\n",
    "\n",
    "\n",
    "    # count the occurrences of each point\n",
    "    c = Counter(zip(x_filtered,y_filtered))\n",
    "    # create a list of the sizes, here multiplied by 10 for scale\n",
    "    s = [10*c[(xx,yy)] for xx,yy in zip(x_filtered,y_filtered)]\n",
    "    plt.scatter(x_filtered, y_filtered, s=s, color='orange')\n",
    "    \n",
    "    plt.xlabel(left_hand_side_column)\n",
    "    plt.ylabel(target_column)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
