{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install necessary requirements\n",
    "%pip install -r ../requirements.txt\n",
    "\n",
    "# Change working directory to root\n",
    "import os\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    %cd ..\n",
    "    print(os.getcwd())\n",
    "\n",
    "# Automatically reload changes in code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from association_finder.concept_drifts_finder import ConceptDriftsFinder\n",
    "from association_finder.models import Transaction, ConceptDriftResult\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and parse file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def preprocess(df, train_params: Optional[TrainParams] = None):\n",
    "    \n",
    "#     # Defining numeric and categorical columns\n",
    "#     numeric_columns = df.dtypes[(df.dtypes == \"float64\") | (df.dtypes == \"int64\")].index.tolist()\n",
    "#     very_numerical = [nc for nc in numeric_columns if df[nc].nunique() > 20]\n",
    "#     categorical_columns = [c for c in df.columns if c not in numeric_columns]\n",
    "#     ordinals = list(set(numeric_columns) - set(very_numerical))\n",
    "\n",
    "#     # Filling Null Values with the column's mean\n",
    "#     na_columns = df[very_numerical].isna().sum()\n",
    "#     na_columns = na_columns[na_columns > 0]\n",
    "\n",
    "#     na_columns_mean = {}\n",
    "        \n",
    "#     for nc in na_columns.index:\n",
    "#         if train_params is None:\n",
    "#             column_mean = df[nc].mean()\n",
    "\n",
    "#             # Save mean\n",
    "#             na_columns_mean[nc] = column_mean\n",
    "#         else:\n",
    "#             column_mean = train_params.na_columns_mean[nc]\n",
    "\n",
    "#         df[nc].fillna(column_mean, inplace=True)\n",
    "\n",
    "#     # print(na_columns_mean,'\\n')\n",
    "    \n",
    "#     # Dropping and filling NA values for categorical columns:\n",
    "#     # drop if at least 70% are NA:\n",
    "#     nul_cols = df[categorical_columns].isna().sum() / len(df)\n",
    "#     drop_us = nul_cols[nul_cols > 0.7]\n",
    "    \n",
    "#     # print('nul_cols: ',nul_cols,'\\n')\n",
    "#     # print('drop_us: ',drop_us,'\\n')\n",
    "    \n",
    "#     df = df.drop(drop_us.index, axis=1)\n",
    "\n",
    "#     # Fill with a new 'na' category:\n",
    "#     categorical_columns = list(set(categorical_columns) - set(drop_us.index))\n",
    "#     df[categorical_columns] = df[categorical_columns].fillna('na')\n",
    "\n",
    "#     # Fill Null values in ordinals with a new '-1' ordinal:\n",
    "#     df[ordinals] = df[ordinals].fillna(-1)\n",
    "\n",
    "#     # Turn Yes/No columns into 1/0 columns, respectively.\n",
    "#     df['RainToday']= df.RainToday.map(dict(Yes=1, No=0))\n",
    "#     df['RainTomorrow'] = df.RainTomorrow.map(dict(Yes=1, No=0))\n",
    "    \n",
    "#     df = df.copy()\n",
    "\n",
    "#     # Bin numerical data\n",
    "#     numerical_columns_cut = {}\n",
    "#     for c in very_numerical:\n",
    "#         if train_params is None:\n",
    "#             try:\n",
    "#                 # df[c] = pd.qcut(df[c], 5, labels=[\"very low\", \"low\", \"medium\", \"high\", \"very high\"])\n",
    "#                 df[c], bins = pd.qcut(df[c], 5, labels=[1, 2, 3, 4, 5], retbins=True)\n",
    "#             except:\n",
    "#                 # sometimes for highly skewed data, we cannot perform qcut as most quantiles are equal\n",
    "#                 # df[c] = pd.cut(df[c], 5, labels=[\"very low\", \"low\", \"medium\", \"high\", \"very high\"])\n",
    "#                 df[c], bins = pd.cut(df[c], 5, labels=[1, 2, 3, 4, 5], retbins=True)\n",
    "\n",
    "#             # Make bin edges larger (infinity and -infinity)\n",
    "#             bins = np.concatenate(([-np.inf], bins[1:-1], [np.inf]))\n",
    "\n",
    "#             # Save bin\n",
    "#             numerical_columns_cut[c] = bins\n",
    "            \n",
    "#         else:\n",
    "#             # Use existing train bins\n",
    "#             bins = train_params.numerical_columns_cut[c]\n",
    "#             df[c] = pd.cut(df[c], labels=[1, 2, 3, 4, 5], bins=bins)\n",
    "        \n",
    "#     return df, TrainParams(na_columns_mean, numerical_columns_cut),[d for d in drop_us.keys()]\n",
    "\n",
    "# def split_X_y(df_prep: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "#     X_columns = list(set(good_columns) - set(train_params.dropped_columns) - {target_column})\n",
    "#     X = df_prep[X_columns]\n",
    "\n",
    "#     for one_hot_column in one_hot_columns:\n",
    "#         X = pd.concat([X, pd.get_dummies(X[one_hot_column], prefix=one_hot_column)], axis=1)\n",
    "#         X = X.drop(columns=[one_hot_column])\n",
    "\n",
    "#     y = df_prep[target_column]\n",
    "    \n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from association_finder.preprocessing import preprocess_dataset, split_X_y\n",
    "from typing import Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "train_dataset_path = \"datasets/rain_in_australia/weatherAUS.csv\"\n",
    "# df = pd.read_csv(train_dataset_path)\n",
    "df = pd.read_csv(train_dataset_path, index_col='Date')\n",
    "\n",
    "# Drop rows with NaN values in the following columns.\n",
    "df.drop(df[df['RainToday'].isna()].index,inplace=True)\n",
    "df.drop(df[df['RainTomorrow'].isna()].index,inplace=True)\n",
    "\n",
    "# Turn Yes/No columns into 1/0 columns, respectively.\n",
    "df['RainToday']= df.RainToday.map(dict(Yes=1, No=0))\n",
    "df['RainTomorrow'] = df.RainTomorrow.map(dict(Yes=1, No=0))\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.3)\n",
    "\n",
    "df_train_prep, train_params = preprocess_dataset(df_train)\n",
    "\n",
    "# Focusing on prominent columns:\n",
    "good_columns = [column for column in ['Location', 'MinTemp', 'MaxTemp',# 'Rainfall',\n",
    "                                      #'Evaporation',\n",
    "                'Sunshine', 'WindGustDir', 'WindSpeed9am','WindSpeed3pm', 'Humidity9am','Humidity3pm',\n",
    "                'WindGustSpeed',#'Pressure9am','Pressure3pm','Cloud9am','Cloud3pm','Temp9am','Temp3pm', 'WindDir9am', 'WindDir3pm',\n",
    "                                      'RainToday','RainTomorrow']\n",
    "                if column not in train_params.dropped_columns]\n",
    "\n",
    "target_column = \"RainTomorrow\"\n",
    "\n",
    "one_hot_columns = [column for column in ['Location', 'WindGustDir'] if column not in train_params.dropped_columns] #'Date', ,'RainToday','RainTomorrow']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import Tuple\n",
    "\n",
    "X_train, y_train = split_X_y(df_train_prep, good_columns, train_params, one_hot_columns, target_column)\n",
    "X_val, y_val = split_X_y(preprocess_dataset(df_val, train_params)[0], good_columns, train_params, one_hot_columns, target_column)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=10000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Train accuracy: {clf.score(X_train, y_train)}\")\n",
    "print(f\"Validation accuracy: {clf.score(X_val, y_val)}\")\n",
    "# Train accuracy: 0.8448883666274971\n",
    "# Validation accuracy: 0.85072792588391\n",
    "\n",
    "# Train accuracy: 0.8194416305360833\n",
    "# Validation accuracy: 0.8177349215352618\n",
    "\n",
    "# Train accuracy: 0.8211434823128976\n",
    "# Validation accuracy: 0.8209491397239553"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model using rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from association_finder.concept_engineering import ConceptEngineering\n",
    "\n",
    "concept_engineering = ConceptEngineering(verbose=True)\n",
    "X_train_rules = concept_engineering.fit_transform(X_train, df_train_prep[good_columns], target_column, one_hot_columns)\n",
    "X_val_rules = concept_engineering.transform(X_val)\n",
    "\n",
    "clf_rules = LogisticRegression(random_state=0, max_iter=10000).fit(X_train_rules, y_train)\n",
    "\n",
    "print(f\"Train accuracy: {clf_rules.score(X_train_rules, y_train)}\")\n",
    "print(f\"Validation accuracy: {clf_rules.score(X_val_rules, y_val)}\")\n",
    "\n",
    "# TODO: Same accuracy before and after the rules.\n",
    "# TODO: If all features are in good_columns, this cell runs a long long time (couldn't get an accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.min_rows\", 200)\n",
    "concept_engineering.concepts_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
