{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: efficient_apriori in /Users/dorin/.local/lib/python3.8/site-packages (from -r ../requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: dataclasses_json in /Users/dorin/.local/lib/python3.8/site-packages (from -r ../requirements.txt (line 2)) (0.5.6)\n",
      "Requirement already satisfied: pandas in /Applications/JupyterLab.app/Contents/Resources/jlab_server/lib/python3.8/site-packages (from -r ../requirements.txt (line 3)) (1.3.5)\n",
      "Requirement already satisfied: scikit-learn in /Users/dorin/.local/lib/python3.8/site-packages (from -r ../requirements.txt (line 4)) (1.0.2)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/dorin/.local/lib/python3.8/site-packages (from dataclasses_json->-r ../requirements.txt (line 2)) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/dorin/.local/lib/python3.8/site-packages (from dataclasses_json->-r ../requirements.txt (line 2)) (3.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/dorin/.local/lib/python3.8/site-packages (from dataclasses_json->-r ../requirements.txt (line 2)) (0.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Applications/JupyterLab.app/Contents/Resources/jlab_server/lib/python3.8/site-packages (from pandas->-r ../requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Applications/JupyterLab.app/Contents/Resources/jlab_server/lib/python3.8/site-packages (from pandas->-r ../requirements.txt (line 3)) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Applications/JupyterLab.app/Contents/Resources/jlab_server/lib/python3.8/site-packages (from pandas->-r ../requirements.txt (line 3)) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Applications/JupyterLab.app/Contents/Resources/jlab_server/lib/python3.8/site-packages (from scikit-learn->-r ../requirements.txt (line 4)) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/dorin/.local/lib/python3.8/site-packages (from scikit-learn->-r ../requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/dorin/.local/lib/python3.8/site-packages (from scikit-learn->-r ../requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/JupyterLab.app/Contents/Resources/jlab_server/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->-r ../requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/dorin/.local/lib/python3.8/site-packages (from typing-inspect>=0.4.0->dataclasses_json->-r ../requirements.txt (line 2)) (4.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/dorin/.local/lib/python3.8/site-packages (from typing-inspect>=0.4.0->dataclasses_json->-r ../requirements.txt (line 2)) (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/dorin/Desktop/Tabular Data Science/Association-Rules-for-Concept-Drifting\n",
      "/Users/dorin/Desktop/Tabular Data Science/Association-Rules-for-Concept-Drifting\n"
     ]
    }
   ],
   "source": [
    "# Install necessary requirements\n",
    "%pip install -r ../requirements.txt\n",
    "\n",
    "# Change working directory to root\n",
    "import os\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    %cd ..\n",
    "    print(os.getcwd())\n",
    "\n",
    "# Automatically reload changes in code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from association_finder.concept_drifts_finder import ConceptDriftsFinder\n",
    "from association_finder.models import Transaction, ConceptDriftResult\n",
    "logging.basicConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and parse file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 28)\n",
      "(15480, 27)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "train_dataset_path = \"datasets/netflix_data/netflix-rotten-tomatoes-metacritic-imdb.csv\"\n",
    "# df = pd.read_csv(train_dataset_path)\n",
    "df = pd.read_csv(train_dataset_path, index_col='Title')\n",
    "\n",
    "# df.drop('Boxoffice', inplace=True, axis=1)\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.3)\n",
    "\n",
    "@dataclass\n",
    "class TrainParams:\n",
    "    \n",
    "    na_columns_mean: Dict[int, float]\n",
    "    numerical_columns_cut: Dict[str, List[float]]\n",
    "    # dropped_columns: List[str] = None\n",
    "    \n",
    "        \n",
    "def preprocess(df, train_params: Optional[TrainParams] = None):\n",
    "    \n",
    "    # Defining numeric and categorical columns\n",
    "    numeric_columns = df.dtypes[(df.dtypes == \"float64\") | (df.dtypes == \"int64\")].index.tolist()\n",
    "    very_numerical = [nc for nc in numeric_columns if df[nc].nunique() > 20]\n",
    "    categorical_columns = [c for c in df.columns if c not in numeric_columns]\n",
    "    ordinals = list(set(numeric_columns) - set(very_numerical))\n",
    "\n",
    "    # Filling Null Values with the column's mean\n",
    "    na_columns = df[very_numerical].isna().sum()\n",
    "    na_columns = na_columns[na_columns > 0]\n",
    "\n",
    "    na_columns_mean = {}\n",
    "    \n",
    "    # flag = True if train_params is None else False\n",
    "    \n",
    "    for nc in na_columns.index:\n",
    "        if train_params is None:\n",
    "            column_mean = df[nc].mean()\n",
    "\n",
    "            # Save mean\n",
    "            na_columns_mean[nc] = column_mean\n",
    "        else:\n",
    "            column_mean = train_params.na_columns_mean[nc]\n",
    "\n",
    "        df[nc].fillna(column_mean, inplace=True)\n",
    "\n",
    "\n",
    "    # Dropping and filling NA values for categorical columns:\n",
    "    # drop if at least 70% are NA:\n",
    "    # nul_cols = df[categorical_columns].isna().sum() / len(df)\n",
    "    # drop_us = nul_cols[nul_cols > 0.7]\n",
    "    # df = df.drop(drop_us.index, axis=1)\n",
    "    \n",
    "#     if flag:\n",
    "#         dropped_columns= [d for d in drop_us.keys()]\n",
    "#     else:\n",
    "#         if train_params.dropped_columns is not None:\n",
    "#             print(df)\n",
    "#             print(train_params.dropped_columns)\n",
    "#             print(df.columns.get_loc(train_params.dropped_columns[0]))\n",
    "#             df = df.drop(df.columns.get_loc(train_params.dropped_columns[0]), axis=1)\n",
    "#             # df = df.drop(df[train_params.dropped_columns[0]].index, axis=1)\n",
    "    \n",
    "    # Fill with a new 'na' category:\n",
    "    categorical_columns = list(set(categorical_columns))# - set(drop_us.index))\n",
    "    df[categorical_columns] = df[categorical_columns].fillna('na')\n",
    "\n",
    "    # Fill Null values in ordinals with a new '-1' ordinal:\n",
    "    df[ordinals] = df[ordinals].fillna(-1)\n",
    "    \n",
    "    df = df.copy()\n",
    "\n",
    "    # Bin numerical data\n",
    "    numerical_columns_cut = {}\n",
    "    for c in very_numerical:\n",
    "        if train_params is None:\n",
    "            try:\n",
    "                # df[c] = pd.qcut(df[c], 5, labels=[\"very low\", \"low\", \"medium\", \"high\", \"very high\"])\n",
    "                df[c], bins = pd.qcut(df[c], 5, labels=[1, 2, 3, 4, 5], retbins=True)\n",
    "            except:\n",
    "                # sometimes for highly skewed data, we cannot perform qcut as most quantiles are equal\n",
    "                # df[c] = pd.cut(df[c], 5, labels=[\"very low\", \"low\", \"medium\", \"high\", \"very high\"])\n",
    "                df[c], bins = pd.cut(df[c], 5, labels=[1, 2, 3, 4, 5], retbins=True)\n",
    "\n",
    "            # Make bin edges larger (infinity and -infinity)\n",
    "            bins = np.concatenate(([-np.inf], bins[1:-1], [np.inf]))\n",
    "\n",
    "            # Save bin\n",
    "            numerical_columns_cut[c] = bins\n",
    "            \n",
    "        else:\n",
    "            # Use existing train bins\n",
    "            bins = train_params.numerical_columns_cut[c]\n",
    "            df[c] = pd.cut(df[c], labels=[1, 2, 3, 4, 5], bins=bins)\n",
    "        \n",
    "    return df, TrainParams(na_columns_mean, numerical_columns_cut)#,[d for d in drop_us.keys()]\n",
    "\n",
    "df_train_prep, train_params = preprocess(df_train)\n",
    "# df_train_prep, train_params, dropped_columns = preprocess(df_train)\n",
    "# print (dropped_columns)\n",
    "\n",
    "# Focusing on prominent columns:\n",
    "good_columns = ['Genre', 'Languages', 'Series or Movie', 'Hidden Gem Score','Country Availability','Runtime',\n",
    "                'Director', 'Writer', 'View Rating', 'IMDb Score', 'Rotten Tomatoes Score','Metacritic Score',\n",
    "               'Awards Received','Awards Nominated For','Release Date','Netflix Release Date','IMDb Votes']\n",
    "                #if column not in dropped_columns]\n",
    "                #'Summary','Production House','Actors','Tags','Boxoffice',\n",
    "# TODO: Check where Amit took the good columns list from\n",
    "\n",
    "target_column = 'Hidden Gem Score' # TODO: What is the target column?? Is it Hidden Gem Score?\n",
    "\n",
    "one_hot_columns =  ['Genre','Languages','Series or Movie','Country Availability','Runtime','Director','Writer','View Rating',\n",
    "                  'Release Date','Netflix Release Date']#'Boxoffice',\n",
    "\n",
    "def split_X_y(df_prep: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    X_columns = list(set(good_columns) - {target_column})#-set(dropped_columns)\n",
    "    X = df_prep[X_columns]\n",
    "\n",
    "    for one_hot_column in one_hot_columns:\n",
    "        X = pd.concat([X, pd.get_dummies(X[one_hot_column], prefix=one_hot_column)], axis=1)\n",
    "        X = X.drop(columns=[one_hot_column])\n",
    "\n",
    "    y = df_prep[target_column]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10836, 26240)\n",
      "(4644, 13588)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorin/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import Tuple\n",
    "\n",
    "X_train, y_train = split_X_y(df_train_prep)\n",
    "print(X_train.shape)\n",
    "X_val, y_val = split_X_y(preprocess(df_val, train_params)[0])\n",
    "print(X_val.shape)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# TODO: Issue with different dropped columns in the train and in the validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9480435585086748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorin/.local/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Country Availability_Argentina,Australia,Japan,United States,Brazil,Mexico,Colombia\n",
      "- Country Availability_Argentina,Australia,Switzerland,Sweden,Belgium,France,Spain,Germany,Portugal,India,Czech Republic,Slovakia,Lithuania,Russia,Greece,Romania,South Africa,Singapore,South Korea,United States,Mexico,Canada,United Kingdom,Poland,Hong Kong,Japan,Iceland,Thailand,Hungary,Turkey,Malaysia,Brazil,Netherlands,Italy,Israel,Colombia\n",
      "- Country Availability_Argentina,Brazil,United Kingdom,Australia,Switzerland,Sweden,Netherlands,Belgium,France,India,Iceland,Germany,Portugal,Lithuania,Russia,South Africa,Slovakia,Czech Republic,Hungary,Greece,Romania,Poland,Singapore,United States,Canada,Mexico,South Korea,Spain,Hong Kong,Japan,Israel,Italy,Thailand,Turkey,Malaysia,Colombia\n",
      "- Country Availability_Argentina,Brazil,United Kingdom,Australia,Switzerland,Sweden,Netherlands,Belgium,France,Spain,Germany,India,Iceland,Portugal,Lithuania,Russia,Slovakia,Czech Republic,Hungary,South Africa,Greece,Romania,Poland,Singapore,United States,Canada,South Korea,Hong Kong,Japan,Israel,Italy,Thailand,Mexico,Turkey,Malaysia,Colombia\n",
      "- Country Availability_Argentina,Brazil,United Kingdom,Australia,Switzerland,Sweden,Netherlands,Belgium,Spain,France,India,Iceland,Germany,Portugal,Russia,Lithuania,South Africa,Slovakia,Czech Republic,Greece,Poland,Romania,Singapore,Israel,South Korea,United States,Canada,Mexico,Hong Kong,Japan,Italy,Thailand,Hungary,Turkey,Malaysia,Colombia\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Country Availability_Argentina,Australia,United States,Brazil,Mexico,Colombia\n",
      "- Country Availability_Argentina,Brazil,Australia,Sweden,Switzerland,Belgium,France,Netherlands,Spain,Germany,Iceland,Portugal,Lithuania,Slovakia,Czech Republic,Romania,Poland,Russia,Greece,India,South Africa,Singapore,Israel,Hong Kong,United States,Canada,Mexico,South Korea,United Kingdom,Japan,Italy,Thailand,Hungary,Turkey,Malaysia,Colombia\n",
      "- Country Availability_Argentina,Brazil,Australia,Sweden,Switzerland,Belgium,France,Netherlands,Spain,Germany,Iceland,Portugal,Slovakia,Lithuania,Czech Republic,Romania,Russia,India,Poland,Greece,South Africa,Singapore,Israel,United Kingdom,United States,Mexico,Canada,South Korea,Hong Kong,Japan,Italy,Thailand,Hungary,Turkey,Malaysia,Colombia\n",
      "- Country Availability_Argentina,Brazil,Australia,Switzerland,Sweden,Belgium,France,Spain,Germany,Iceland,India,Portugal,Lithuania,Russia,Czech Republic,Slovakia,Hungary,South Africa,Romania,Poland,Israel,Singapore,Hong Kong,United States,Mexico,South Korea,Canada,Japan,Italy,Thailand,United Kingdom,Netherlands,Turkey,Colombia\n",
      "- Country Availability_Argentina,Brazil,Canada,Mexico,United States,Belgium,Hungary,Hong Kong,South Korea,Israel,Poland,Romania,Greece,South Africa,Portugal,Germany,France,Iceland,India,Spain,Sweden,Netherlands,Switzerland,Australia,United Kingdom,Czech Republic,Russia,Lithuania,Singapore,Slovakia,Japan,Italy,Thailand,Turkey,Malaysia,Colombia\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 13588 features, but LogisticRegression is expecting 26240 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/q1/nfrt7s991s1bypv7fk4sswrm0000gn/T/ipykernel_4595/3638412969.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Train accuracy: {clf.score(X_train, y_train)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Validation accuracy: {clf.score(X_val, y_val)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36mscore\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    649\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    650\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 651\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    652\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    653\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_more_tags\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    423\u001B[0m             \u001B[0mVector\u001B[0m \u001B[0mcontaining\u001B[0m \u001B[0mthe\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0meach\u001B[0m \u001B[0msample\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    424\u001B[0m         \"\"\"\n\u001B[0;32m--> 425\u001B[0;31m         \u001B[0mscores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecision_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    426\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscores\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    427\u001B[0m             \u001B[0mindices\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mscores\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001B[0m in \u001B[0;36mdecision_function\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    405\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    406\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 407\u001B[0;31m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"csr\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    408\u001B[0m         \u001B[0mscores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msafe_sparse_dot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdense_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mintercept_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    409\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    583\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    584\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mcheck_params\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ensure_2d\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 585\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_n_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    586\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    587\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_check_n_features\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    398\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    399\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mn_features\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_features_in_\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 400\u001B[0;31m             raise ValueError(\n\u001B[0m\u001B[1;32m    401\u001B[0m                 \u001B[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    402\u001B[0m                 \u001B[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: X has 13588 features, but LogisticRegression is expecting 26240 features as input."
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {clf.score(X_train, y_train)}\")\n",
    "print(f\"Validation accuracy: {clf.score(X_val, y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model using rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from association_finder.concept_engineering import ConceptEngineering\n",
    "\n",
    "concept_engineering = ConceptEngineering()\n",
    "X_train_rules = concept_engineering.fit_transform(X_train, df_train_prep[good_columns], target_column, one_hot_columns)\n",
    "X_val_rules = concept_engineering.transform(X_val)\n",
    "\n",
    "clf_rules = LogisticRegression(random_state=0).fit(X_train_rules, y_train)\n",
    "\n",
    "print(f\"Train accuracy: {clf_rules.score(X_train_rules, y_train)}\")\n",
    "print(f\"Validation accuracy: {clf_rules.score(X_val_rules, y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "concept_engineering.concepts_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}